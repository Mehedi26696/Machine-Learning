{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0b86aa-836f-4741-be9b-7801044d8c46",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:limegreen\">Support Vector Machine</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28cb147-2194-4e7c-815e-2b66fa08ccd6",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression tasks. While it can be applied to regression problems, SVM is best suited for classification tasks. The primary objective of the SVM algorithm is to identify the optimal hyperplane in an N-dimensional space that can effectively separate data points into different classes in the feature space. The algorithm ensures that the margin between the closest points of different classes, known as support vectors, is maximized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e9085d2-d96b-4df3-b8e4-4425353a1b56",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Overview\n",
    "\n",
    "## 1. Overview\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. It operates by identifying the hyperplane that best separates data points into distinct classes.\n",
    "\n",
    "## 2. How SVM Works\n",
    "- **Hyperplane**: A decision boundary that divides the dataset into classes.\n",
    "- **Support Vectors**: Data points closest to the hyperplane that influence its position and orientation.\n",
    "- **Margin**: The distance between the hyperplane and the nearest support vectors. SVM aims to maximize this margin.\n",
    "\n",
    "## 3. Key Concepts\n",
    "- **Kernel Function**: Transforms data into higher-dimensional spaces to handle non-linear separation. Common kernels include:\n",
    "  - Linear\n",
    "  - Polynomial\n",
    "  - Radial Basis Function (RBF)\n",
    "- **C Parameter (Regularization)**: Controls the trade-off between achieving a larger margin and minimizing classification error. A smaller C encourages a wider margin but allows more misclassification, while a larger C focuses on classifying all training points correctly.\n",
    "- **Gamma (Kernel Coefficient)**: Determines the influence of a single training example. Low values of gamma imply that points far away from the hyperplane influence the decision boundary, whereas high values of gamma imply that only points close to the hyperplane have an impact.\n",
    "- **Hinge Loss**: A loss function used to penalize misclassified points or points within the margin.\n",
    " \n",
    " <img src=\"1.png\">  <img src=\"2.png\"> \n",
    "  <img src=\"3.png\"> <img src=\"4.png\"> \n",
    "## 4. Applications of SVM\n",
    "- Text categorization\n",
    "- Image classification\n",
    "- Bioinformatics (e.g., cancer classification)\n",
    "\n",
    "## 5. Advantages and Limitations\n",
    "### Advantages:\n",
    "- Effective in high-dimensional spaces.\n",
    "- Works well with clear margin of separation.\n",
    "- Robust against overfitting when the number of dimensions exceeds the number of samples.\n",
    "\n",
    "### Limitations:\n",
    "- Computationally expensive for large datasets.\n",
    "- Performance depends heavily on the choice of kernel and hyperparameters.\n",
    "- Not ideal for overlapping classes.\n",
    "\n",
    "## 6. Practical Notes\n",
    "- **Linear SVM**: Suitable for linearly separable data.\n",
    "- **Nonlinear SVM**: Uses kernels like RBF to handle complex, non-linear relationships.\n",
    "- Hyperparameter tuning (e.g., C, gamma) is critical for optimal performance.\n",
    "\n",
    "## Summary\n",
    "SVM is a powerful algorithm for both linear and non-linear classification problems. Its effectiveness hinges on proper kernel selection and parameter optimization. While computationally intensive for large datasets, it remains a preferred choice for tasks requiring high accuracy in well-structured data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5d9343c-5e0a-4322-95ff-707f9af93aae",
   "metadata": {},
   "source": [
    " <img src=\"5.png\"> <img src=\"6.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73a782-06f6-4df9-91c4-c2efdbff7f48",
   "metadata": {},
   "source": [
    " <img src=\"7.png\"> <img src=\"8.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba470b1-f1be-40f9-b0bc-aea9db30cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
